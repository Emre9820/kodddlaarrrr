import os
import numpy as np
import pandas as pd
import joblib
from collections import defaultdict
import matplotlib.pyplot as plt # Grafik çizimi için eklendi

from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import accuracy_score, classification_report
from sklearn.model_selection import train_test_split

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import torch.nn.functional as F # Softmax için eklendi
from torch.optim.lr_scheduler import ReduceLROnPlateau # Scheduler için eklendi

# Reproducibility için seed ayarı
np.random.seed(42)
torch.manual_seed(42)

###############################################
# Veri Yükleme Fonksiyonu (Sadece _a.csv - Mevcut kodda _a.csv okunuyor)
###############################################
def load_data(data_dir, mode='train'):
    """
    Verileri yükler ve özellik çıkarımı yapar (sadece _a.csv).
    """
    data_a = [] # _a.csv verisi için
    labels = []  # Eğitim için gerçek etiketler (ana/alt)
    file_labels = []  # Tahmin modunda gerçek etiket bilgisini saklamak için

    for main_folder in os.listdir(data_dir):
        main_class_path = os.path.join(data_dir, main_folder)
        if not os.path.isdir(main_class_path):
            continue

        for path, _, _ in os.walk(main_class_path):
            if path == main_class_path:
                continue

            for file_name in os.listdir(path):
                # Mevcut kodda _a.csv okunuyor, ona göre devam ediyorum.
                # Eğer _i.csv isteniyorsa burayı "_i.csv" olarak değiştirin.
                if file_name.endswith("_a.csv"):
                    try:
                        file_path = os.path.join(path, file_name)
                        df_a = pd.read_csv(file_path, skiprows=28)
                        feat_a = df_a.iloc[:, 1].values.flatten()
                        data_a.append(feat_a)

                        true_label = os.path.join(
                            os.path.basename(os.path.dirname(path)),
                            os.path.basename(path)
                        )
                        if mode == 'train':
                            labels.append(true_label)
                        else:
                            file_labels.append(true_label)
                    except Exception as e:
                        print(f"Hata: {file_name} işlenirken hata oluştu: {e}. Atlanıyor.")

    if mode == 'train':
        return np.array(data_a), labels
    else:
        return np.array(data_a), file_labels

###############################################
# ANN Model Tanımı (Değişiklik yok)
###############################################
class ANN(nn.Module):
    def __init__(self, input_size, hidden_size, num_classes):
        super(ANN, self).__init__()
        self.fc1 = nn.Linear(input_size, hidden_size)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(hidden_size, num_classes)

    def forward(self, x):
        out = self.fc1(x)
        out = self.relu(out)
        out = self.fc2(out)
        return out

###############################################
# PyTorch Dataset Tanımı (Değişiklik yok)
###############################################
class SpectralDataset(Dataset):
    def __init__(self, X, y):
        self.X = X
        self.y = y

    def __len__(self):
        return len(self.X)

    def __getitem__(self, idx):
        sample = torch.tensor(self.X[idx], dtype=torch.float32)
        label = torch.tensor(self.y[idx], dtype=torch.long)
        return sample, label


###############################################
# Tahmin Sonuçlarını Grup Bazında Raporlama (Değişiklik yok)
###############################################
def print_grouped_predictions_summary(predictions):
    import pandas as pd
    df = pd.DataFrame(predictions, columns=['Gerçek', 'Tahmin', 'Olasılık'])

    grouped_true = df.groupby('Gerçek')
    total_correct_predictions = 0
    total_wrong_predictions = 0

    for true_label, group in grouped_true:
        total = len(group)
        true_main = true_label.split('/')[0]

        # Doğru tahmin: tahmin edilen etiketin ana kısmı gerçek ana ile eşleşiyorsa
        correct_mask = group['Tahmin'].apply(lambda x: x.split('/')[0] == true_main)
        correct_group = group[correct_mask]
        correct_count = len(correct_group)
        accuracy = (correct_count / total) * 100 if total > 0 else 0

        print(f"Gerçek: {true_label}")
        print(f"  Doğru tahminler ({true_main}): {correct_count} dosya, Doğruluk: %{accuracy:.2f}")

        total_correct_predictions += correct_count
        total_wrong_predictions += (total - correct_count)

        wrong_group = group[~correct_mask]
        if not wrong_group.empty:
            # Yanlış tahminleri alt klasörleriyle birlikte grupla
            wrong_summary = wrong_group.groupby('Tahmin').agg(
                count=('Tahmin', 'count'),
                avg_prob=('Olasılık', 'mean')
            ).reset_index()
            wrong_summary = wrong_summary.sort_values(by='count', ascending=False).head(3)

            print("  Yanlış tahminler:")
            for _, row in wrong_summary.iterrows():
                print(f"    {row['Tahmin']}: {row['count']} dosya, Ortalama Olasılık: {row['avg_prob']:.4f}")
        print("")

    total_predictions = len(predictions)
    overall_accuracy = (total_correct_predictions / total_predictions) * 100 if total_predictions > 0 else 0
    print(
        f"Toplamda {total_predictions} prediction verisinden, {total_correct_predictions} doğru, {total_wrong_predictions} yanlış veri var. Doğruluk oranı: %{overall_accuracy:.2f}")

def print_class_based_accuracy(predictions):
    """
    Her sınıf için doğru ve yanlış tahmin sayısını ve doğruluğunu hesaplar ve yazdırır.
    """
    import pandas as pd
    df = pd.DataFrame(predictions, columns=['Gerçek', 'Tahmin', 'Olasılık'])

    all_classes = set(df['Gerçek'].unique())
    all_classes.update(df['Tahmin'].unique())

    for class_name in sorted(all_classes):

        class_df = df[df['Gerçek'] == class_name]
        if class_df.empty:
            continue

        total_samples = len(class_df)
        correct_predictions = len(class_df[class_df['Gerçek'] == class_df['Tahmin']])

        accuracy = (correct_predictions / total_samples) * 100 if total_samples > 0 else 0

        print(f"Sınıf: {class_name}")
        print(f"  Toplam örnek: {total_samples}")
        print(f"  Doğru tahmin: {correct_predictions}")
        print(f"  Yanlış tahmin: {total_samples - correct_predictions}")
        print(f"  Doğruluk: %{accuracy:.2f}")
        print("")

###############################################
# Ana Fonksiyon: Eğitim ve Tahmin (ANN) - Güncellendi
###############################################
def main():
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    ##############################
    # 1. Eğitim
    ##############################
    TRAIN_DIR = "/home/han/Documents/500_veri/Train"

    print("Eğitim verisi yükleniyor...")
    # Mevcut kodda _a.csv okunuyor, ona göre data_a kullanılıyor.
    data_a, train_labels = load_data(TRAIN_DIR, mode='train')
    print(f"Eğitim verisi boyutu: {data_a.shape}\n")

    # Tüm veriyi %80 eğitim, %20 doğrulama olarak ayırma
    data_a_train, data_a_val, train_labels_train, train_labels_val = train_test_split(
        data_a, train_labels, test_size=0.2, random_state=42, stratify=train_labels
    )

    # Etiket kodlama (ana/alt şeklinde)
    y_encoder = LabelEncoder()
    y_train = y_encoder.fit_transform(train_labels_train)
    y_val = y_encoder.transform(train_labels_val)
    joblib.dump(y_encoder, "label_encoder.pkl")

    # Dataset oluşturma
    train_dataset = SpectralDataset(data_a_train, y_train)
    val_dataset = SpectralDataset(data_a_val, y_val)
    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)

    # ANN modelini oluştur
    input_size = data_a_train.shape[1]
    hidden_size = 128 # Bu değeri ihtiyaca göre ayarlayabilirsiniz
    num_classes = len(np.unique(y_train))
    model = ANN(input_size, hidden_size, num_classes).to(device)

    # Loss fonksiyonu, optimizer ve LR scheduler
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=0.001) # Başlangıç öğrenme oranı
    # ReduceLROnPlateau: val_loss 5 epoch iyileşmezse LR'yi 0.1 ile çarpar
    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=True)

    # Eğitim parametreleri ve Early Stopping için değişkenler
    num_epochs = 500 # Maksimum epoch sayısı (early stopping ile daha erken durabilir)
    early_stop_patience = 10 # Kaç epoch iyileşme olmazsa durdurulacak
    early_stop_counter = 0
    best_val_loss = float('inf')
    best_epoch = -1
    best_train_loss = float('inf')
    best_train_acc = 0.0
    best_val_acc = 0.0

    # Grafik için listeler
    train_losses = []
    val_losses = []
    train_accuracies = []
    val_accuracies = []

    print("ANN modeli eğitiliyor...\n")
    for epoch in range(num_epochs):
        # --- Eğitim Aşaması ---
        model.train()
        running_train_loss = 0.0
        correct_train = 0
        total_train = 0
        for inputs, labels in train_loader:
            inputs, labels = inputs.to(device), labels.to(device)

            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            running_train_loss += loss.item() * inputs.size(0)
            _, predicted = torch.max(outputs.data, 1)
            total_train += labels.size(0)
            correct_train += (predicted == labels).sum().item()

        epoch_train_loss = running_train_loss / total_train
        epoch_train_acc = correct_train / total_train * 100
        train_losses.append(epoch_train_loss)
        train_accuracies.append(epoch_train_acc)

        # --- Doğrulama Aşaması ---
        model.eval()
        running_val_loss = 0.0
        correct_val = 0
        total_val = 0
        with torch.no_grad():
            for inputs, labels in val_loader:
                inputs, labels = inputs.to(device), labels.to(device)
                outputs = model(inputs)
                loss = criterion(outputs, labels)
                running_val_loss += loss.item() * inputs.size(0)
                _, predicted = torch.max(outputs.data, 1)
                total_val += labels.size(0)
                correct_val += (predicted == labels).sum().item()

        epoch_val_loss = running_val_loss / total_val
        epoch_val_acc = correct_val / total_val * 100
        val_losses.append(epoch_val_loss)
        val_accuracies.append(epoch_val_acc)

        print(f'Epoch [{epoch+1}/{num_epochs}] - Train Loss: {epoch_train_loss:.4f}, Train Acc: {epoch_train_acc:.2f}% | Val Loss: {epoch_val_loss:.4f}, Val Acc: {epoch_val_acc:.2f}%')

        # LR Scheduler'ı güncelle
        scheduler.step(epoch_val_loss)

        # --- Early Stopping ve En İyi Modeli Kaydetme ---
        if epoch_val_loss < best_val_loss:
            best_val_loss = epoch_val_loss
            best_epoch = epoch + 1
            best_train_loss = epoch_train_loss # En iyi epoch'taki train loss
            best_train_acc = epoch_train_acc   # En iyi epoch'taki train acc
            best_val_acc = epoch_val_acc     # En iyi epoch'taki val acc
            early_stop_counter = 0
            # En iyi modeli kaydet
            torch.save(model.state_dict(), "best_ann_model.pth")
            print(f"Epoch {epoch+1}: Validation loss düştü ({best_val_loss:.4f}). Model kaydedildi.")
        else:
            early_stop_counter += 1
            print(f"Epoch {epoch+1}: Validation loss düşmedi. Sayaç: {early_stop_counter}/{early_stop_patience}")
            if early_stop_counter >= early_stop_patience:
                print("Erken durdurma tetiklendi!")
                break # Eğitim döngüsünü sonlandır

    print(f"\nEğitim tamamlandı.")
    print(f"En iyi epoch: {best_epoch} - Train Loss: {best_train_loss:.4f}, Train Acc: {best_train_acc:.2f}% | Val Loss: {best_val_loss:.4f}, Val Acc: {best_val_acc:.2f}%")
    print("En iyi model 'best_ann_model.pth' olarak kaydedildi.\n")

    # --- Grafik Çizimi ---
    plt.figure(figsize=(12, 5))

    plt.subplot(1, 2, 1)
    plt.plot(range(1, len(train_losses) + 1), train_losses, label='Train Loss')
    plt.plot(range(1, len(val_losses) + 1), val_losses, label='Validation Loss')
    plt.axvline(best_epoch, linestyle='--', color='r', label=f'Best Epoch ({best_epoch})')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.title('Training and Validation Loss')
    plt.legend()
    plt.grid(True)

    plt.subplot(1, 2, 2)
    plt.plot(range(1, len(train_accuracies) + 1), train_accuracies, label='Train Accuracy')
    plt.plot(range(1, len(val_accuracies) + 1), val_accuracies, label='Validation Accuracy')
    plt.axvline(best_epoch, linestyle='--', color='r', label=f'Best Epoch ({best_epoch})')
    plt.xlabel('Epochs')
    plt.ylabel('Accuracy (%)')
    plt.title('Training and Validation Accuracy')
    plt.legend()
    plt.grid(True)

    plt.tight_layout()
    plt.show()


    ##############################
    # 2. Tahmin (En İyi Modeli Kullanarak)
    ##############################
    SAMPLE_DIR = "/home/han/Documents/Prediction"
    print("\nTahmin verileri yükleniyor...")
    try:
        # Sadece _a.csv yükle (eğitimde kullanılanla aynı olmalı)
        data_a_pred, true_labels = load_data(SAMPLE_DIR, mode='predict')

        # Tahmin için Dataset ve DataLoader
        # Tahmin için etiketler önemli değil, geçici bir dizi verilebilir (np.zeros)
        pred_dataset = SpectralDataset(data_a_pred, np.zeros(len(data_a_pred)))
        pred_loader = DataLoader(pred_dataset, batch_size=1, shuffle=False) # batch_size=1 genellikle tahmin için uygundur

        # En iyi modeli yükle
        print("En iyi model ('best_ann_model.pth') yükleniyor...")
        # Model mimarisini tekrar tanımla ve kaydedilen ağırlıkları yükle
        model = ANN(input_size, hidden_size, num_classes).to(device)
        model.load_state_dict(torch.load("best_ann_model.pth", map_location=device))
        model.eval() # Modeli değerlendirme moduna al
        y_encoder = joblib.load("label_encoder.pkl") # Kaydedilen encoder'ı yükle

        # Tahmin yap ve olasılıkları al
        predictions = []
        with torch.no_grad():
            for idx, (inputs, _) in enumerate(pred_loader):
                inputs = inputs.to(device)
                outputs = model(inputs)
                # Olasılıkları almak için softmax uygula
                probs = F.softmax(outputs, dim=1).cpu().numpy().flatten()
                pred_idx = np.argmax(probs)
                pred_class = y_encoder.inverse_transform([pred_idx])[0]
                pred_prob = float(probs[pred_idx]) # En yüksek olasılık değeri
                true_label = true_labels[idx]
                predictions.append((true_label, pred_class, pred_prob))

        print("\n--- Tahmin Sonuçları ---")
        print_grouped_predictions_summary(predictions)
        print("\n--- Sınıf Bazlı Doğruluk ---")
        print_class_based_accuracy(predictions)
        print("\nTahmin işlemi başarıyla tamamlandı!")

    except FileNotFoundError:
        print(f"Hata: 'best_ann_model.pth' veya 'label_encoder.pkl' bulunamadı. Lütfen önce modeli eğitin.")
    except Exception as e:
        print(f"Tahmin sırasında bir hata oluştu: {str(e)}")

if __name__ == "__main__":
    main()

